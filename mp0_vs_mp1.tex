\documentclass[eikonal.tex]{subfiles}

\begin{document}

\section{Comparing $F_0$ and $F_1$}

\textbf{TODO}: add an introduction to this section and some words
about \texttt{mp0}.

In what follows, we assume that $s > \smin > 0$ where $\smin$ is
independent of $h$ and that $s$ is Lipschitz continuous with $O_h(1)$
Lipschitz constant.

\begin{lemma}\label{lemma:bounded-inv-hess-F1}
  There is a constant $\beta = O(h^{-1})$ such that
  $\norm{\nabla^2 F_1(\lambda)^{-1}} \leq \beta$ for all
  $\lambda \in \Delta^n$.
\end{lemma}

\begin{proof}
  From \cref{eq:hess-F1}, if we temporarily define:
  \begin{equation}
    A = \frac{s^\theta_\lambda h}{l_\lambda} \delta P^\top \mathcal{P}^\perp_\lambda \delta P \mbox{ and } B = \frac{\theta h}{l_\lambda} \anticom{\delta P^\top p_\lambda, \delta s},
  \end{equation}
  we can see that:
  \begin{equation}
    \norm{A^{-1} B} = \frac{\theta}{s^\theta_\lambda} \norm{\parens{\delta P^\top \mathcal{P}^\perp_\lambda \delta P}^{-1} \anticom{\delta P^\top p_\lambda, \delta s}} = O(h),
  \end{equation}
  since $1/s \leq 1/\smin$ and $\norm{\delta s} = O(h)$. Hence,
  $\norm{A^{-1} B} < 1$ for $h$ small enough, and we can Taylor
  expand:
  \begin{equation}
    \nabla^2 F_1(\lambda)^{-1} = \parens{A + B}^{-1} = A^{-1} \parens{I + A^{-1}B}^{-1} = A^{-1} \parens{I - A^{-1} B + A^{-2} B^2 - + \cdots},
  \end{equation}
  which implies $\norm{\nabla^2 F_1(\lambda)^{-1}} = O(h^{-1})$. To
  define $\beta$, let:
  \begin{equation}
    \beta = \max_{\lambda \in \Delta^n} \norm{\nabla^2 F_1(\lambda)^{-1}} = O(h^{-1}),
  \end{equation}
  completing the proof.
\end{proof}

\begin{lemma}\label{lemma:bounded-first-step}
  There is a constant $\alpha = O(h)$ such that
  $\norm{\nabla^2 F_1(\lambda_{0}^*)^{-1} \nabla F_1(\lambda_{0}^*)}
  \leq \alpha$.
\end{lemma}

\begin{proof}
  From \cref{lemma:bounded-inv-hess-F1} we have
  $\norm{F_1(\lambda_0^*)^{-1}} = O(h^{-1})$, so to establish the
  result we only need to show that
  $\norm{\nabla F_1(\lambda_0^*)} = O(h^2)$. To this end, let
  $\underline{\lambda} = {(n + 1)}^{-1} \m{1}_{n \times 1}$ (i.e., the
  centroid of $\Delta^n$, where $s^\theta$ is evaluated). Then,
  $s^\theta_\lambda = s^\theta + \delta s^\top (\lambda -
  \underline{\lambda})$ so that, for a general $\lambda$:
  \begin{equation}
    \label{eq:grad-F1-in-terms-of-grad-F0}
    \nabla F_1(\lambda) = l_\lambda h \delta s + \delta u + \frac{s^\theta + \delta s^\top (\lambda - \underline{\lambda})}{l_\lambda} h \delta P^\top p_\lambda = l_\lambda h \delta s + \nabla F_0(\lambda) + \frac{\delta s^\top {(\lambda - \underline{\lambda})}}{l_\lambda} h \delta P^\top p_\lambda.
  \end{equation}
  Since $\nabla F_0(\lambda_0) = 0$ by optimality, we can conclude
  using \cref{eq:grad-F1-in-terms-of-grad-F0} and
  $\norm{\delta s} = O(h)$ that:
  \begin{equation}
    \norm{\nabla F_1(\lambda_0)} = h \norm{l_{\lambda_0} \delta s + \frac{\delta s^\top {(\lambda - \underline{\lambda})}}{l_{\lambda_0}} \delta P^\top p_\lambda} = O(h^2),
  \end{equation}
  which proves the result.
\end{proof}

\begin{lemma}\label{lemma:hess-F1-lipschitz}
  The Hessian $\nabla^2 F_1$ is Lipschitz continuous with $O(h)$
  Lipschitz constant. That is, there is some constant $\gamma = O(h)$
  so that for two points $\lambda$ and $\lambda'$:
  \begin{align*}
    \norm{\nabla^2 F_1(\lambda) - \nabla^2 F_1(\lambda')} \leq \gamma \norm{\lambda - \lambda'}.
  \end{align*}
\end{lemma}

\begin{proof}
  If we restrict our attention to $\Delta^n$, we can see that:
  $l_\lambda^{-1} \delta P^\top \mathcal{P}_\lambda^\perp \delta P$
  and
  $\tfrac{\theta}{l_\lambda} \anticom{\delta P^\top p_\lambda, \delta
    s}$ are each Lipschitz continuous with Lipschitz constants that
  are $O_h(1)$. Then, since $s^\theta_\lambda$ is Lipschitz continuous
  with an $O_h(1)$ Lipschitz constant, it follows that
  $A(\lambda) = \tfrac{s^\theta h}{l_\lambda} \delta P^\top
  \mathcal{P}^\perp_\lambda \delta P$ is Lipschitz with a constant
  that is $O(h)$ over $\Delta^n$, using the notation of
  \cref{lemma:bounded-inv-hess-F1}; the same is true of
  $B(\lambda) = \tfrac{\theta h}{l_\lambda} \anticom{\delta P^\top
    p_\lambda, \delta s}$. Since
  $\nabla^2 F_1(\lambda) = A(\lambda) + B(\lambda)$, we can see
  immediately that it is also Lipschitz on $\Delta^n$ with a constant
  that is $O(h)$.
\end{proof}

\begin{theorem}\label{theorem:mp0-newton}
  Let $h$ be sufficiently small so that $F_1$ is strictly
  convex. Then, the error vector
  $\delta\lambda^* = \lambda_1^* - \lambda_0^*$ satisfies
  $\norm{\delta\lambda^*} = O(h)$. Additionally, if we let
  $\lambda_0 = \lambda_0^*$ in the following iteration:
  \begin{equation}
    \label{eq:lam0-iter-to-lam1}
    \lambda_{k+1} \gets \lambda_k - \nabla^2 F_1(\lambda_k)^{-1} \nabla F_1(\lambda_k), \qquad k = 0, 1, \hdots,
  \end{equation}
  then this iteration is well-defined, and converges quadratically to
  $\lambda_1^*$.
\end{theorem}

\begin{proof}
  For our situation, Theorem 5.3.2 of Stoer and
  Burlisch~\cite{stoer2013introduction} indicates that if:
  \begin{enumerate}
  \item $\norm{\nabla F_1(\lambda)^{-1}} \leq \beta$,\label{item:sb-newton-1}
  \item $\norm{\nabla F_1(\lambda_0^*)^{-1} \nabla F_1(\lambda_0^*)} \leq \alpha$,\label{item:sb-newton-2}
  \item and
    $\norm{\nabla F_1(\lambda) - \nabla F_1(\lambda')} \leq \gamma
    \norm{\lambda - \lambda'}$ for each
    $\lambda, \lambda' \in \Delta^n$,\label{item:sb-newton-3}
  \end{enumerate}
  then with $\lambda_0 = \lambda_0^*$, the iteration
  \cref{eq:lam0-iter-to-lam1} is well-defined, with each iterate
  satisfying $\norm{\lambda_k - \lambda_0} \leq r$, where
  $r = \alpha/(1 - \alpha\beta\gamma/2)$. Additionally, the limit of
  this iteration exists, and the iteration converges to it
  quadratically; we note that since $F_1$ is strictly convex, the
  limit of the iteration must be $\lambda_1^*$, so the theorem also
  gives us
  $\norm{\delta\lambda^*} = \norm{\lambda_1^* - \lambda_0^*} \leq r$.

  Now, we note that
  \cref{item:sb-newton-1,item:sb-newton-2,item:sb-newton-3} correspond
  exactly to
  \cref{lemma:bounded-inv-hess-F1,lemma:bounded-first-step,lemma:hess-F1-lipschitz},
  which gave us values for $\alpha, \beta$, and $\gamma$. All that
  remains is to compute $r$. Since the preceding lemmas imply
  $\alpha\beta\gamma = O(h)$, hence $\alpha\beta\gamma/2 < 1$ for $h$
  small enough. We have:
  \begin{equation}
    r = \frac{\alpha}{1 - \frac{\alpha\beta\gamma}{2}} = \alpha + \alpha^2 + \alpha^3 + \cdots = O(h),
  \end{equation}
  so that $\norm{\delta\lambda^*} = O(h)$, and the result follows.
\end{proof}

\begin{corollary}
  The error incurred by the \texttt{mp0} method is $O(h^3)$ per
  update; i.e.:
  \begin{equation}
    \label{eq:mp0-error}
    \abs{F_1(\lambda_1^*) - F_1(\lambda_0^*)} = O(h^3).
  \end{equation}
\end{corollary}

\begin{proof}
  From \cref{theorem:mp0-newton}, we have
  $\norm{\delta\lambda^*} = O(h)$. Then, Taylor expanding
  $F_1(\lambda_0^*)$, we get:
  \begin{equation*}
    F_1(\lambda_0^*)
    = F_1(\lambda_1^* - \delta \lambda^*) = F_1(\lambda_1^*) - \nabla F_1(\lambda_1^*)^\top \delta\lambda^* + \frac{1}{2} \delta\lambda^* \nabla F_1^2(\lambda_1^*) \delta\lambda^* + R,
  \end{equation*}
  where $\abs{R} = O(\norm{\delta\lambda^*}^3)$. Since $\lambda_1^*$
  is optimum, $\nabla F_1(\lambda_1^*) = 0$. Hence:
  \begin{equation*}
    \abs{F_1(\lambda_1^*) - F_1(\lambda_0^*)} \leq \frac{1}{2} \norm{\nabla F_1^2(\lambda_1^*)} \norm{\delta\lambda^*}^2 + O(\norm{\delta\lambda^*}^3) = O(h^3),
  \end{equation*}
  which proves the result.
\end{proof}

\begin{remark}
  If we exchange the roles of $F_0$ and $F_1$---i.e., if we start from
  $\lambda_1^*$ and perform a Newton iteration on $\nabla F_0$---we
  can obtain the foregoing error bound again, and possibly with less
  effort. The main reason to start from $\lambda_0^*$ and drive to
  $\lambda_1^*$ is that it allows us to use \texttt{mp0} as a means
  of initializing \texttt{mp1}. For $d = 1, 2$, this is unimportant,
  but in higher dimensions, minimizing $F_0$ should be
  cheaper. Reducing the number of $F_1$ update iterations should allow
  for a sped-up method with the same accuracy.
\end{remark}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
