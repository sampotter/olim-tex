\documentclass[eikonal.tex]{subfiles}

\begin{document}

\section{Proofs for section
  \ref{ssec:minimization-problem}}\label{sec:minimization-proofs}

\begin{proof}[Proof of \cref{prop:F0-grad-and-Hess}]
  For the gradient, we have:
  \begin{equation*}
    \nabla_\lambda F_0(\lambda; \theta) = \delta u + \frac{s^{\theta} h}{2 l_\lambda} \nabla_\lambda p_\lambda^\top p_\lambda = \delta u + \frac{s^{\theta} h}{l_\lambda} \delta P^\top p_\lambda,
  \end{equation*}
  since
  $\nabla_\lambda p_\lambda^\top p_\lambda = 2 \delta P^\top
  p_\lambda$. For the Hessian:
  \begin{align*}
    \nabla^2_\lambda F_0(\lambda; \theta) &= \nabla_\lambda \parens{\frac{s^{\theta} h}{l_\lambda} p_\lambda^\top \delta P} = s^{\theta} h \parens{\nabla_\lambda \frac{1}{l_\lambda} p_\lambda^\top \delta P + \frac{1}{l_\lambda} \nabla_\lambda p_\lambda^\top \delta P} \\
    &= \frac{s^{\theta} h}{l_\lambda} \parens{\delta P^\top \delta P - \frac{\delta P^\top p_\lambda p_\lambda^\top \delta P}{p_\lambda^\top p_\lambda}} = \frac{s^{\theta} h}{l_\lambda} \delta P^\top \parens{I - \frac{p_\lambda p_\lambda^\top}{p_\lambda^\top p_\lambda}} \delta P,
  \end{align*}
  from which the result follows.
\end{proof}

\begin{proof}[Proof of \cref{prop:F1-grad-and-Hess}]
  Since $F_1(\lambda; \theta) = u_\lambda + h s^{\theta}_\lambda l_\lambda$, for the gradient we have:
  \begin{equation*}
    \nabla_\lambda F_1(\lambda; \theta) = \delta u + h \parens{\theta l_\lambda \delta s + \frac{s^{\theta}_\lambda}{2l_\lambda} \nabla_\lambda p_\lambda^\top p_\lambda} = \delta u + \frac{h}{l_\lambda} \parens{\theta p_\lambda^\top p_\lambda \delta s + s^{\theta} \delta P^\top p_\lambda},
  \end{equation*}
  and for the Hessian:
  \begin{equation*}
    \nabla_\lambda^2 F_1(\lambda; \theta) = \frac{h}{2 l_\lambda} \parens{\theta \parens{\nabla_\lambda p_\lambda^\top p_\lambda \delta s^\top + \delta s {(\nabla_\lambda p_\lambda^\top p_\lambda)}^\top} + s^{\theta}_\lambda \parens{\frac{1}{2 p_\lambda^\top p_\lambda} \nabla_\lambda p_\lambda^\top p_\lambda {(\nabla_\lambda p_\lambda^\top p_\lambda)}^\top - \nabla^2_\lambda p_\lambda^\top p_\lambda}}.
  \end{equation*}
  Simplfying this gives us the result.
\end{proof}

\begin{proof}[Proof of \cref{lemma:dPt-cprojp-dP-pd}]
  % To show that $\delta P^\top \mathcal{P}^\perp_{p_\lambda} \delta P$
  % is positive semidefinite, we simply note that since
  % $\mathcal{P}^\perp_{p_\lambda}$ is an orthogonal projector, it is
  % positive semidefinite, and its singular value decomposition can be
  % written $UU^\top$, where $U \in \mathbb{R}^{n+1 \times n}$. Then:
  % \begin{equation}\label{eq:dPt-cprojp-dP-gram}
  %   \delta P^\top \mathcal{P}^\perp_{p_\lambda} \delta P = {(U^\top \delta P)}^\top {(U^\top \delta P)}.
  % \end{equation}
  % From the factorization in \cref{eq:dPt-cprojp-dP-gram}, we can see
  % that $\delta P^\top \mathcal{P}^\perp_{p_\lambda} \delta P$ is a
  % Gram matrix, hence positive semidefinite.

  Let $\nu_\lambda = p_\lambda/l_\lambda \in \mathbb{R}^n$ be the unit
  vector in the direction of $p_\lambda$, and assume that
  $Q = \begin{bmatrix} \nu_\lambda & U \end{bmatrix} \in \mathbb{R}^{n
    \times n}$ is orthonormal. Then:
  \begin{equation}
    \delta P^\top \mathcal{P}^\perp_{p_\lambda} \delta P = \delta P^\top {(I - \nu_\lambda \nu_\lambda^\top)} \delta P = \delta P^\top {(QQ^\top - \nu_\lambda \nu_\lambda^\top)} \delta P = \delta P^\top U U^\top \delta P.
  \end{equation}
  Hence, $\delta P^\top \mathcal{P}^\perp \delta P$ is a Gram matrix
  and positive semidefinite.

  Next, since $\Delta^n$ is nondegenerate, the vectors $p_i$ for
  $i = 0, \hdots, n - 1$ are linearly independent. Since the $i$th
  column of $\delta P$ is $\delta p_i = p_i - p_0$, we can see that
  the vector $p_0$ is not in the range of $\delta P$; hence, there is
  no vector $\mu$ such that $\delta P \mu = \alpha p_\lambda$, for any
  $\alpha \neq 0$. What's more, by definition,
  $\text{ker}(\mathcal{P}_{p_\lambda}^\perp) = \langle p_\lambda
  \rangle$. So, we can see that
  $\mathcal{P}^\perp_{p_\lambda} \delta P \mu = 0$ only if $\mu = 0$,
  from which we can conclude
  $\delta P^\top \mathcal{P}^\perp_{p_\lambda} \delta P \succ
  0$. Altogether, bearing in mind that $\smin$ is assumed to be
  positive, we conclude that $\nabla^2 F_0$ is positive definite.
\end{proof}

\begin{proof}[Proof of \cref{lemma:F-strictly-convex}]
  To show that $\nabla^2 F_1$ is positive definite for $h$ small
  enough, note from \cref{eq:hess-F1} that $\nabla^2 F_1$ is the sum
  of a positive definite matrix and a small, indefinite
  perturbation. To use this fact, note that since
  $\delta P^\top \mathcal{P}^\perp_\lambda \delta P$ is symmetric
  positive definite, it has an eigenvalue decomposition
  $Q \Lambda Q^\top$ where $\Lambda_{ii} > 0$ for all $i$. Since
  $\delta P^\top \mathcal{P}^\perp_\lambda \delta P$ doesn't depend on
  $h$, for a fixed set of vectors $p_0, \hdots, p_n$, we can expect
  its eigenvalues to be constant with respect to $h$. So, if we write:
  \begin{equation}
    A = \frac{s^\theta_\lambda h}{l_\lambda} \delta P^\top \mathcal{P}^\perp_\lambda \delta P = Q \parens{\frac{s^\theta_\lambda h}{l_\lambda} \Lambda} Q^\top
  \end{equation}
  we can expect this matrix's eigenvalues to be $\Theta(h)$; in
  particular, $\lambda_{\min} \geq C h$ for some constant $C$,
  provided that $s > \smin > 0$, as assumed. This gives us a bound for
  the positive definite part of $\nabla F_1^2$.

  Now, consider the indefinite perturbation,
  $B = \set{\delta P^\top \nu_\lambda, \theta h \delta s}$. Since
  $\norm{\delta s} = O(h)$, we find that:
  \begin{equation}
    \lambda_{\max}(B) = \norm{\anticom{\delta P^\top \nu_\lambda,
        \theta h \delta s}}_2 \leq \theta h \sqrt{n} \norm{\anticom{\delta P^\top \nu_\lambda, \delta s}}_\infty = O(h^2),
  \end{equation}
  where we use the fact that the Lipschitz constant of $s$ is
  $K \leq C$, so that:
  \begin{equation}
    |\delta s_i| = |s_i - s_0| \leq K |x_i - x_0| \leq K h \sqrt{n}
    \leq Ch \sqrt{n},
  \end{equation}
  for each $i$. Letting $z \neq 0$, we compute:
  \begin{equation}
    z^\top \nabla^2 F_1 z = z^\top A z + z^\top B z \geq \lambda_{\min}(A) z^\top z + z^\top B z \geq Ch z^\top z + z^\top B z.
  \end{equation}
  Now, since
  $\abs{z^\top B z} \leq \abs{\lambda_{\max}(B)} z^\top z \leq D h^2
  z^\top z$, where $D$ is some positive constant, we can see that for
  $h$ small enough, it must be the case that
  $Ch z^\top z + z^\top B z > 0$; i.e., that $\nabla^2 F_1$ is
  positive definite; consequently, $F_1$ is strictly convex in this case.
\end{proof}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "sisc-eikonal"
%%% End:
