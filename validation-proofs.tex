\documentclass[eikonal.tex]{subfiles}

\begin{document}

\section{Proofs for section
  \ref{ssec:validation}}\label{app:validation-proofs} In this section, we establish some technical lemmas that we will use
to validate the use of
\texttt{mp0}. \Cref{lemma:bounded-inv-hess-F1,lemma:bounded-first-step,lemma:hess-F1-lipschitz}
set up the conditions for \cref{thm:stoer-bulirsch} of Stoer and
Bulirsch~\cite{stoer2013introduction}, from which
\cref{theorem:mp0-newton} readily follows.

\begin{lemma}\label{lemma:bounded-inv-hess-F1}
  There exists $\beta = O(h^{-1})$ s.t.
  $\norm{\nabla^2 F_1(\lambda)^{-1}} \leq \beta$ for all
  $\lambda \in \Delta^n$.
\end{lemma}

\begin{proof}[Proof of \cref{lemma:bounded-inv-hess-F1}]
  To simplify \cref{eq:hess-F1}, we temporarily define:
  \begin{equation}
    A = \frac{s^\theta_\lambda h}{l_\lambda} \delP^\top \mathcal{P}^\perp_\lambda \delP \mbox{ and } B = \frac{\theta h}{l_\lambda} \anticom{\delP^\top p_\lambda, \dels}.
  \end{equation}
  Observe that $\|A\| = O(h)$ and $\|B\| = O(h^2)$, since
  $\|\delta s\| = O(h)$ and since all other factors involved in $A$
  and $B$ (excluding $h$ itself) are independent of $h$. Hence:
  \begin{equation}
    \norm{A^{-1} B} = \frac{\theta}{s^\theta_\lambda} \norm{\parens{\delP^\top \mathcal{P}^\perp_\lambda \delP}^{-1} \anticom{\delP^\top p_\lambda, \dels}} = O(h),
  \end{equation}
  since $1/s \leq 1/\smin$ and $\norm{\dels} = O(h)$. Hence,
  $\norm{A^{-1} B} < 1$ for $h$ small enough, and we can Taylor
  expand:
  \begin{equation}
    \begin{aligned}
      \nabla^2 F_1(\lambda)^{-1} &= \parens{A + B}^{-1} = {(I + A^{-1} B)}^{-1} A^{-1} \\
      &= \parens{I - A^{-1} B + {(A^{-1} B)}^2 - \cdots} A^{-1} \\
      &= A^{-1} - A^{-1} B A^{-1} + {(A^{-1} B)}^2 A^{-1} - \,\cdots,
    \end{aligned}
  \end{equation}
  which implies $\norm{\nabla^2 F_1(\lambda)^{-1}} = O(h^{-1})$. Note
  that when we Taylor expand, $\|A^{-1} B\| = O(h)$, so that
  $\|A^{-1} B\| < 1$ for $h$ small enough. To define $\beta$, let:
  \begin{equation}
    \beta = \max_{\lambda \in \Delta^n} \norm{\nabla^2 F_1(\lambda)^{-1}} = O(h^{-1}),
  \end{equation}
  completing the proof.
\end{proof}

\begin{lemma}\label{lemma:bounded-first-step}
  There exists $\alpha = O(h)$ s.t.
  $\norm{\nabla^2 F_1(\lambda_{0}^*)^{-1} \nabla F_1(\lambda_{0}^*)}
  \leq \alpha$.
\end{lemma}

\begin{proof}[Proof of \cref{lemma:bounded-first-step}]
  From \cref{lemma:bounded-inv-hess-F1} we have
  $\norm{F_1(\lambda_0^*)^{-1}} = O(h^{-1})$, so to establish the
  result we only need to show that
  $\norm{\nabla F_1(\lambda_0^*)} = O(h^2)$. To this end, let
  $\underline{\lambda} = {(n + 1)}^{-1} \m{1}_{n \times 1}$ (i.e., the
  centroid of $\Delta^n$, where $s^\theta$ is evaluated). Then,
  recalling \cref{fig:slowness-tetra},
  $s^\theta_\lambda = s^\theta + \dels^\top (\lambda -
  \underline{\lambda})$ so that, for a general $\lambda$:
  \begin{equation}\label{eq:grad-F1-in-terms-of-grad-F0}
    \begin{aligned}
      \nabla F_1(\lambda) &= l_\lambda h \dels + \delU + \frac{s^\theta + \dels^\top (\lambda - \underline{\lambda})}{l_\lambda} h \delP^\top p_\lambda \\
      &= l_\lambda h \dels + \nabla F_0(\lambda) + \frac{\dels^\top {(\lambda - \underline{\lambda})}}{l_\lambda} h \delP^\top p_\lambda.
    \end{aligned}
  \end{equation}
  Since $\nabla F_0(\lambda_0^*) = 0$ by optimality, we can conclude
  using \cref{eq:grad-F1-in-terms-of-grad-F0} and
  $\norm{\dels} = O(h)$ that:
  \begin{equation}
    \norm{\nabla F_1(\lambda_0^*)} = h \norm{l_{\lambda_0^*} \dels + \frac{\dels^\top {(\lambda - \underline{\lambda})}}{l_{\lambda_0^*}} \delP^\top p_\lambda} = O(h^2),
  \end{equation}
  which proves the result.
\end{proof}

\begin{lemma}\label{lemma:hess-F1-lipschitz}
  The Hessian $\nabla^2 F_1$ is Lipschitz continuous with $O(h)$
  Lipschitz constant. That is, there is some constant $\gamma = O(h)$
  so that for two points $\lambda$ and $\lambda'$:
  \begin{align*}
    \norm{\nabla^2 F_1(\lambda) - \nabla^2 F_1(\lambda')} \leq \gamma \norm{\lambda - \lambda'}.
  \end{align*}
\end{lemma}

\begin{proof}[Proof of \cref{lemma:hess-F1-lipschitz}]
  If we restrict our attention to $\Delta^n$, we see that
  $l_\lambda^{-1} \delP^\top \mathcal{P}_\lambda^\perp \delP$ is
  Lipschitz continuous function of $\lambda$ with $O(1)$ Lipschitz
  constant and $\theta \{{\delP}^\top p_\lambda, \dels\} /l_{\lambda}$
  is Lipschitz continuous with $O(h)$ Lipschitz constant since
  $\|\delta s\| = O(h)$. Then, since $s^\theta_\lambda$ is $O(1)$
  Lipschitz, it follows that:
  \begin{equation}
    A(\lambda) = \tfrac{s^\theta_\lambda h}{l_\lambda} \delP^\top
    \mathcal{P}^\perp_\lambda \delP
  \end{equation}
  has a Lipschitz constant that is $O(h)$ for $\lambda \in \Delta^n$,
  using the notation of \cref{lemma:bounded-inv-hess-F1}. Likewise,
  \begin{equation}
    B(\lambda) = \tfrac{\theta h}{l_\lambda} \anticom{\delP^\top
      p_\lambda, \dels} = O(h^2),
  \end{equation}
  since it is a sum of two terms involving products of $h$ and
  $\delta s$. Since $\nabla^2 F_1(\lambda) = A(\lambda) + B(\lambda)$,
  we can see immediately that it is also Lipschitz on $\Delta^n$ with
  a constant that is $O(h)$.
\end{proof}

\begin{proof}[Proof of \cref{theorem:mp0-newton}]
  Our proof of \cref{theorem:mp0-newton} relies on the following
  theorem on the convergence of Newton's method, which we present for
  convenience.

  \begin{theorem}[Theorem 5.3.2, Stoer and Bulirsch]\label{thm:stoer-bulirsch}
    Let $C \subseteq \R^n$ be an open set, let $C_0$ be a convex set
    with $\overline{C}_0 \subseteq C$, and let
    $f : C \to \mathbb{R}^n$ be differentiable for $x \in C_0$ and
    continuous for $x \in C$. For $x_0 \in C_0$, let
    $r, \alpha, \beta, \gamma$ satisfy
    $S_r(x_0) = \set{x : \norm{x - x_0} < r} \subseteq C_0$,
    $\mu = \alpha\beta\gamma < 2$, $r = \alpha(1 - \mu)^{-1}$, and let
    $f$ satisfy:
    \begin{enumerate}[label=(\alph*)]
    \item for all $x, y \in C_0$,
      $\norm{D f(x) - D f(y)} \leq \gamma \norm{x - y}$,
    \item for all $x \in C_0$, $(D f(x))^{-1}$ exists and satisfies
      $\norm{(Df(x))^{-1}} \leq \beta$,
    \item and $\norm{(Df(x_0))^{-1} f(x_0)} \leq \alpha$.
    \end{enumerate}
    Then, beginning at $x_0$, each iterate:
    \begin{equation}
      x_{k+1} = x_k - Df(x_k)^{-1} f(x_k), \qquad k = 0, 1, \hdots,
    \end{equation}
    is well-defined and satisfies $\norm{x_k - x_0} < r$ for all
    $k \geq 0$. Furthermore, $\lim_{k \to \infty} x_k = \xi$ exists and
    satisfies $\norm{\xi - x_0} \leq r$ and $f(\xi) = 0$.
  \end{theorem}

  For our situation, Theorem 5.3.2 of Stoer and
  Bulirsch~\cite{stoer2013introduction} indicates that if:
  \begin{align}
    \|\nabla F_1(\lambda)^{-1}\| &\leq \beta, \mbox{where } \beta = O(h^{-1}) \label{item:sb-newton-1}, \\
    \|\nabla F_1(\lambda_0^*)^{-1} \nabla F_1(\lambda_0^*)\| &\leq \alpha, \mbox{where } \alpha = O(h), \label{item:sb-newton-2} \mbox{ and} \\
    \|\nabla F_1(\lambda) - \nabla F_1(\lambda')\| &\leq \gamma \norm{\lambda - \lambda'} \mbox{ for each } \lambda, \lambda' \in \Delta^n, \mbox{where } \gamma = O(h), \label{item:sb-newton-3}
  \end{align}
  then with $\lambda_0 = \lambda_0^*$, the iteration
  \cref{eq:lam0-iter-to-lam1} is well-defined, with each iterate
  satisfying $\norm{\lambda_k - \lambda_0} \leq r$, where
  $r = \alpha/(1 - \alpha\beta\gamma/2)$. Additionally, the limit of
  this iteration exists, and the iteration converges to it
  quadratically; we note that since $F_1$ is strictly convex for $h$
  small enough, the limit of the iteration must be $\lambda_1^*$, so
  the theorem also gives us
  $\norm{\dellam^*} = \norm{\lambda_1^* - \lambda_0^*} \leq r$.

  Now, we note that
  \cref{item:sb-newton-1,item:sb-newton-2,item:sb-newton-3} correspond
  exactly to
  \cref{lemma:bounded-inv-hess-F1,lemma:bounded-first-step,lemma:hess-F1-lipschitz},
  which gave us values for $\alpha, \beta$, and $\gamma$. All that
  remains is to compute $r$. Since the preceding lemmas imply
  $\alpha\beta\gamma = O(h)$, hence $\alpha\beta\gamma/2 < 1$ for $h$
  small enough. We have:
  \begin{equation}
    r = \frac{\alpha}{1 - \frac{\alpha\beta\gamma}{2}} = \alpha \parens{1 + \frac{\alpha\beta\gamma}{2} + \frac{\alpha^2\beta^2\gamma^2}{4} + \cdots} = O(h),
  \end{equation}
  so that $\norm{\dellam^*} = O(h)$, and the result follows.

  To obtain the $O(h^3)$ error bound, from \cref{theorem:mp0-newton},
  we have $\norm{\dellam^*} = O(h)$. Then, Taylor expanding
  $F_1(\lambda_0^*)$, we get:
  \begin{equation*}
    F_1(\lambda_0^*)
    = F_1(\lambda_1^* - \dellam^*) = F_1(\lambda_1^*) - \nabla F_1(\lambda_1^*)^\top \dellam^* + \frac{1}{2} \dellam^* \nabla F_1^2(\lambda_1^*) \dellam^* + R,
  \end{equation*}
  where $\abs{R} = O(\norm{\dellam^*}^3)$. Since $\lambda_1^*$
  is optimum, $\nabla F_1(\lambda_1^*) = 0$. Hence:
  \begin{equation*}
    \abs{F_1(\lambda_1^*) - F_1(\lambda_0^*)} \leq \frac{1}{2} \norm{\nabla F_1^2(\lambda_1^*)} \norm{\dellam^*}^2 + O(\norm{\dellam^*}^3) = O(h^3),
  \end{equation*}
  which proves the result.
\end{proof}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "sisc-eikonal.tex"
%%% End:
